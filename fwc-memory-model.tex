% chapter included in forwardcom.tex
\documentclass[forwardcom.tex]{subfiles}
\begin{document}
\chapter{Модель памяти} \label{memoryModel}
Адресное пространство использует беззнаковые 64--разрядные адреса и 64--разрядные указатели. В будущем возможно расширение до 128--разрядных адресов, но это вряд ли будет уместно в обозримом будущем.

Абсолютные адреса используются редко. Большинство объектов данных, функций, и целей перехода адресуется с помощью смещения (разрядности, не большей 32) относительно некоторой точки отсчёта, содержащейся в 64--разрядном указателе. Этот указатель может быть указателем команд (IP), указателем секции данных (DATAP), указателем стека (SP), или регистром общего назначения.

Приложение может обращаться к следующим разделам данных.
\begin{itemize}
	\item Код программы (CODE). Этот блок является исполняемым, с возможностью чтения, или без неё, но без возможности записи. Секция CODE может разделяться между разными процессами, выполняющими одну и ту же программу.
	\item Константные данные программы (CONST). Она содержит константы и таблицы, используемые программой, без возможности записи. Может разделяться между несколькими процессами.
	\item Статические разделы данных, доступные и для чтения, и для записи, которые могут содержать как инициализированные данные (DATA), так и неинициализированные (BSS). Эти разделы используются для глобальных данных и для статических данных, определённых внутри функций. Необходимо несколько экземпляров, если несколько процессов выполняет один и тот же код. 
	\item Стековые данные (STACK). Данные раздел используется для нестатических данных, определённых внутри функций. Каждый процесс или поток имеет свой собственный стек, адресуемый относительно указателя стека. При добавлении данных в стек, тот растёт вниз, от старших адресов --- к младшим.
	\item Куча программы (HEAP). Используется для динамического выделения памяти прикладной программой.
	\item Данные потока (THREADD). Выделяются, когда поток создаётся, и используются для локальных статических данных потока и для блока окружения потока.
\end{itemize}

Ссылки в пределах секции CODE используют 8--разрядные, 24--разрядные, и 32--разрядные знаковые ссылки относительно указателя команд, умножаемого на размер слова кода, равный 4 байтам. 

Секцию CONST лучше помещать сразу после секции CODE. Данные в секции CONST в основном адресуются относительно указателя команд, без масштабирования\footnote{В случае чистой гарвардской архитектуры, секция CONST может быть помещена в доступную для чтения память программ, чтобы адресовать относительно указателя команд, или может быть помещена в память данных, и адресоваться относительно DATAP}. 

Секции DATA и BSS адресуются относительно указателя секции данных (DATAP), который является специальным регистром, указывающим на некоторую точку отсчёта, расположенную в этих разделах. Предпочтительной точкой отсчёта является место, где DATA заканчивается, а BSS --- начинается. Несколько выполняющихся экземпляров одной и той же программы будут иметь разные значения указателя секции данных. Секции  CODE и CONST содержат не прямые ссылки на  DATA или BSS, а лишь смещения относительно указателя секции данных, что делаем возможным нескольким процессам разделять одни и те же секции CODE и CONST, но иметь собственные закрытые секции DATA и BSS, без необходимости в трансляции виртуальных адресов. Секции DATA и BSS могут размещаться где угодно в адресном пространстве, независимо от того, где размещаются CONST и CODE.

Данные в секции STACK адресуются относительно указателя стека (SP). Данные, находящиеся в куче, адресуются через указатели, предоставленные функцией выделения памяти в куче.

Данные потока адресуются относительно регистра, называемого указателем блока окружения потока, который свой у каждого потока процесса. Блок окружения потока может выделяться в стеке, когда создаётся новый поток.

Секции данных STACK, DATA, BSS, HEAP и THREADD лучше хранить совместно, в непрерывном блоке, чтобы  оптимизировать кэширование и управление памятью. 

Данная модель позволяет программе обращаться к секции CODE размером вплоть до 8Гб, секции CONST --- до 2Гб, секции DATA --- до 2Гб, секции BSS --- до 2Гб, секции THREADD --- до 2Гб, секции STACK почти неограниченного размера, с кадрами по 2Гб, и почти неограниченному количеству данных в секции HEAP. Чтобы обращаться к данным из CONST в том редком случае, когда расстояние между кодом и данными превышает 2Гб, либо чтобы избежать перемещения адресов, в блоке окружения потока предоставляется указатель на секцию CONST. 

Конец объединённого блока данных, находящихся в памяти, должен иметь неиспользуемое пространство того же размера, что и максимальная длина вектора. Это позволит команде restore\_cp читать больше, чем необходимо, при восстановлении вектора неизвестной длины;  а также позволит функции, находящей конец заканчивающейся нулём строки, читать по одному куску размером с длину вектора за раз, не вызывая нарушений доступа из--за чтения в недоступной части памяти.

У большинства микропроцессорных систем стек растёт вниз. У системы ForwardCom дело обстоит так же, но, в основном, по другой причине.
% When a vector register is saved on the stack, it is stored as the length followed by the amount of data indicated by the length. When the vector register is restored (using the restore\_cp instruction), it is necessary to read the length followed by the data. The stack pointer must point to the low end where the length is stored, otherwise it would be impossible to find where the length is stored. 
%
%\section{Thread memory protection} \label{threadMemoryProtection}
%Each thread must have its own stack. The thread data (THREADD) may be placed on this stack. The ForwardCom system allows inter-thread memory protection. The stack data of the main thread of a program is accessible to all its child threads, but all other threads in the program can have private data which is not accessible to any other threads, not even to the main thread. Any communication and synchronization between threads must use static memory or memory belonging to the main thread. 
%\vspace{2mm}
%
%It is recommended to use this inter-thread memory protection in all cases except where legacy software requires one memory space shared by all threads. 
%\vspace{2mm}
%
%\subsubsection{Isolated memory blocks} \label{isolatedMemoryBlocks}
%It is possible to make a system function that allocates an isolated memory block surrounded by inaccessible memory on both sides. Such a memory block, which will be accessible only to a specific thread, can be used for example for an input buffer in cases where security requirements are high. Each thread can have only a limited number of such protected memory blocks because of the limited size of the memory map.
%
%\section{Memory management} \label{memoryManagement}
%It is a design goal to minimize memory fragmentation and to minimize the need for virtual address translation. Current designs often have very complicated memory management systems with multilevel address translation, large translation-lookaside-buffers (TLB), and huge page tables. We want to replace the TLB, which has a large number of fixed-size memory blocks, by a memory map with a few memory blocks of variable size. In most cases, the main thread of an application will only need three blocks of memory: CONST (read only), CODE (execute only), and the combined STACK+DATA+BSS+HEAP (read-write). A child thread needs one more entry for its private stack. Similar blocks are defined for system code. 
%\vspace{2mm}
%
%A memory map with such a limited number of entries can easily be implemented on the chip in a very efficient way and it can easily be changed on task switches. Each process and each thread must have its own memory map. The memory is not organized into fixed-size pages. 
%\vspace{2mm}
%
%The memory map supports virtual address translation in the form of a constant offset that defines the distance between the virtual address and the physical address for each map entry. The hardware should not waste time and power on virtual address translation when it is not used.
%\vspace{2mm}
%
%A limited number of extra entries are provided in the memory map to deal with cases where the memory becomes fragmented, but memory fragmentation can be avoided in most cases. The following techniques are provided to simplify memory management and avoid memory fragmentation:
%
%\begin{itemize}
%\item There is only one type of function libraries which can be used for both static and dynamic linking. These are linked with a mechanism that keeps the CONST, CODE and DATA sections contiguous with the similar sections of the main program in most cases. This technique is described on page \pageref{libraryLinkMethods} below.
%
%\item The required stack size is calculated by the compiler and the linker so that stack overflow can be avoided in most cases. This technique is described on page \pageref{predictingStackSize}.
%
%\item The operating system can keep statistical records of the heap use of each program in order to predict the required heap size. The same technique can be used for predicting stack use in cases where the required stack size cannot be predicted exactly (e. g. recursive function calls). 
%\end{itemize}
%
%The memory space may become fragmented despite the use of these techniques. Problems that can result in memory fragmentation are listed below. 
%
%\begin{itemize}
%\item Recursive functions can use unlimited stack space. We may require that the programmer specifies a maximum recursion level in a pragma.
%
%\item Allocation of variable-size arrays on the stack using the alloca function in C. We may require that the programmer specifies a maximum size. 
%
%\item Runtime linking. The program can reserve space for loading and linking function libraries at run time (see page \pageref{runtimeLinking}). The memory may become fragmented if the memory space reserved for this purpose turns out to be insufficient.
%
%\item Script languages and byte code languages. It is difficult to predict the required size of stack and heap when running interpreted or emulated code. It is recommended to use a just-in-time compiler instead. Self-modifying scripts cannot be compiled. The same problem can occur with large user-defined macros.
%
%\item Unpredictable number of threads without protection. The required stack size for a thread may be computed in advance, but in some cases it may be difficult to predict the number of threads that a program will generate. Multiple threads will mostly share the same code sections, but they need separate stacks. The stack of a thread can be placed anywhere in memory without problems if inter-thread memory protection is used. But if memory is shared between threads and the number of threads is unpredictable then the shared 
%memory space may become fragmented. 
%
%\item Unpredictable heap size. Programs that process large amounts of data, e. g. multimedia processing, may need a large heap. A heap can use discontiguous memory, but this will require extra entries in the memory map. 
%
%\item Lazy loading and code overlay. A large program may have certain code units that are rarely used and loaded only when needed. Lazy loading can be useful to save memory, but it may require virtual memory translation and it may cause memory fragmentation. A straightforward solution is to implement such code units as separate executable programs. 
%
%\item Hot patching, i. e. updating of code while it is running. 
%
%\item Shared memory for inter-process communication. This requires extra entries in the memory map as explained below.
%
%\item Many programs running. The memory can become fragmented when many programs of different sizes are loaded and unloaded randomly or swapped to memory. 
%\end{itemize}
%
%A possible remedy against overflow of stack and heap is to place the STACK, DATA, BSS and HEAP data together (in this order) in an address range with large unused virtual address spaces below and above, so that the stack can grow downwards and the heap can grow upwards into the vacant spaces. This method can avoid fragmentation of the virtual address space, but not the physical address space. Fragmentation of the physical address space can be remedied by moving data from a memory block of insufficient size to another block that is larger. This method has the cost of a time delay when the data are moved. 
%\vspace{2mm}
%
%If runtime linking runs into memory problems and lack of memory map entries then it is allowed to mix CONST and CODE sections together in a common section with both read and execute access. If a library function contains constant data that originate from an untrusted source, while the code is trusted, then it is preferred to put the untrusted data into the DATA section rather than the CONST section in order to prevent execution of malicious code placed in the CONST section.
%\vspace{2mm}
%
%\label{sharedMemory}
%Shared memory can be used when there is a need to transfer large amounts of data between two processes. One process shares a part of its memory with another process. The receiving process needs an extra entry in its memory map to indicate read and/or write access rights to the shared memory block. The process that owns the shared memory block does not need any extra entry in its memory map. There is a limit to how many shared memory blocks an application can receive access to, because we want to keep the memory map small. If one program needs to communicate with a large number of other programs then we can use one of these solutions: (1) let the program that needs many connections own the shared memory and give each of its clients access to one part of it, (2) run multiple threads in (or multiple instances of) the program that needs many connections so that each thread has access to only one shared memory block, (3) let multiple communication channels use the same shared memory block or parts of it, (4) communicate through function calls, (5) communicate through network sockets, or (6) communicate through files. 
%\vspace{2mm}
%
%Executable memory cannot be shared between different applications. The mechanism of interprocess calls must be used if one application needs to call a function in another application. This is described on page \pageref{interProcessCalls}. 
%\vspace{2mm}
%
%We can probably keep memory fragmentation so low, by using the principles discussed here, that a relatively small memory map for each thread will be sufficient to cover normal cases. This will be much more efficient than the large TLB and multilevel address translation of current designs. It will save silicon space and power, and we can avoid the cost of TLB misses and page faults, and it will make task switches very fast.
\end{document}
